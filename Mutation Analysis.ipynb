{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SVQHoNhF02hx"},"outputs":[],"source":["# Import libraries, key resources\n","from Bio.SeqUtils import seq3, seq1\n","from Bio.Seq import Seq\n","import codecs\n","from collections import Counter\n","import csv\n","from datetime import datetime\n","import geopandas as gpd\n","from matplotlib.colors import ListedColormap\n","from matplotlib.dates import DateFormatter, MonthLocator\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","from skbio import DNA\n","from skbio.alignment import local_pairwise_align_ssw\n","from skbio import Protein\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n","import warnings\n","\n","blosum50 = \\\n","    {\n","        '*': {'*': 1, 'A': -5, 'C': -5, 'B': -5, 'E': -5, 'D': -5, 'G': -5,\n","              'F': -5, 'I': -5, 'H': -5, 'K': -5, 'M': -5, 'L': -5,\n","              'N': -5, 'Q': -5, 'P': -5, 'S': -5, 'R': -5, 'T': -5,\n","              'W': -5, 'V': -5, 'Y': -5, 'X': -5, 'Z': -5},\n","        'A': {'*': -5, 'A': 5, 'C': -1, 'B': -2, 'E': -1, 'D': -2, 'G': 0,\n","              'F': -3, 'I': -1, 'H': -2, 'K': -1, 'M': -1, 'L': -2,\n","              'N': -1, 'Q': -1, 'P': -1, 'S': 1, 'R': -2, 'T': 0, 'W': -3,\n","              'V': 0, 'Y': -2, 'X': -1, 'Z': -1},\n","        'C': {'*': -5, 'A': -1, 'C': 13, 'B': -3, 'E': -3, 'D': -4,\n","              'G': -3, 'F': -2, 'I': -2, 'H': -3, 'K': -3, 'M': -2,\n","              'L': -2, 'N': -2, 'Q': -3, 'P': -4, 'S': -1, 'R': -4,\n","              'T': -1, 'W': -5, 'V': -1, 'Y': -3, 'X': -1, 'Z': -3},\n","        'B': {'*': -5, 'A': -2, 'C': -3, 'B': 6, 'E': 1, 'D': 6, 'G': -1,\n","              'F': -4, 'I': -4, 'H': 0, 'K': 0, 'M': -3, 'L': -4, 'N': 5,\n","              'Q': 0, 'P': -2, 'S': 0, 'R': -1, 'T': 0, 'W': -5, 'V': -3,\n","              'Y': -3, 'X': -1, 'Z': 1},\n","        'E': {'*': -5, 'A': -1, 'C': -3, 'B': 1, 'E': 6, 'D': 2, 'G': -3,\n","              'F': -3, 'I': -4, 'H': 0, 'K': 1, 'M': -2, 'L': -3, 'N': 0,\n","              'Q': 2, 'P': -1, 'S': -1, 'R': 0, 'T': -1, 'W': -3, 'V': -3,\n","              'Y': -2, 'X': -1, 'Z': 5},\n","        'D': {'*': -5, 'A': -2, 'C': -4, 'B': 6, 'E': 2, 'D': 8, 'G': -1,\n","              'F': -5, 'I': -4, 'H': -1, 'K': -1, 'M': -4, 'L': -4, 'N': 2,\n","              'Q': 0, 'P': -1, 'S': 0, 'R': -2, 'T': -1, 'W': -5, 'V': -4,\n","              'Y': -3, 'X': -1, 'Z': 1},\n","        'G': {'*': -5, 'A': 0, 'C': -3, 'B': -1, 'E': -3, 'D': -1, 'G': 8,\n","              'F': -4, 'I': -4, 'H': -2, 'K': -2, 'M': -3, 'L': -4, 'N': 0,\n","              'Q': -2, 'P': -2, 'S': 0, 'R': -3, 'T': -2, 'W': -3, 'V': -4,\n","              'Y': -3, 'X': -1, 'Z': -2},\n","        'F': {'*': -5, 'A': -3, 'C': -2, 'B': -4, 'E': -3, 'D': -5,\n","              'G': -4, 'F': 8, 'I': 0, 'H': -1, 'K': -4, 'M': 0, 'L': 1,\n","              'N': -4, 'Q': -4, 'P': -4, 'S': -3, 'R': -3, 'T': -2, 'W': 1,\n","              'V': -1, 'Y': 4, 'X': -1, 'Z': -4},\n","        'I': {'*': -5, 'A': -1, 'C': -2, 'B': -4, 'E': -4, 'D': -4,\n","              'G': -4, 'F': 0, 'I': 5, 'H': -4, 'K': -3, 'M': 2, 'L': 2,\n","              'N': -3, 'Q': -3, 'P': -3, 'S': -3, 'R': -4, 'T': -1,\n","              'W': -3, 'V': 4, 'Y': -1, 'X': -1, 'Z': -3},\n","        'H': {'*': -5, 'A': -2, 'C': -3, 'B': 0, 'E': 0, 'D': -1, 'G': -2,\n","              'F': -1, 'I': -4, 'H': 10, 'K': 0, 'M': -1, 'L': -3, 'N': 1,\n","              'Q': 1, 'P': -2, 'S': -1, 'R': 0, 'T': -2, 'W': -3, 'V': -4,\n","              'Y': 2, 'X': -1, 'Z': 0},\n","        'K': {'*': -5, 'A': -1, 'C': -3, 'B': 0, 'E': 1, 'D': -1, 'G': -2,\n","              'F': -4, 'I': -3, 'H': 0, 'K': 6, 'M': -2, 'L': -3, 'N': 0,\n","              'Q': 2, 'P': -1, 'S': 0, 'R': 3, 'T': -1, 'W': -3, 'V': -3,\n","              'Y': -2, 'X': -1, 'Z': 1},\n","        'M': {'*': -5, 'A': -1, 'C': -2, 'B': -3, 'E': -2, 'D': -4,\n","              'G': -3, 'F': 0, 'I': 2, 'H': -1, 'K': -2, 'M': 7, 'L': 3,\n","              'N': -2, 'Q': 0, 'P': -3, 'S': -2, 'R': -2, 'T': -1, 'W': -1,\n","              'V': 1, 'Y': 0, 'X': -1, 'Z': -1},\n","        'L': {'*': -5, 'A': -2, 'C': -2, 'B': -4, 'E': -3, 'D': -4,\n","              'G': -4, 'F': 1, 'I': 2, 'H': -3, 'K': -3, 'M': 3, 'L': 5,\n","              'N': -4, 'Q': -2, 'P': -4, 'S': -3, 'R': -3, 'T': -1,\n","              'W': -2, 'V': 1, 'Y': -1, 'X': -1, 'Z': -3},\n","        'N': {'*': -5, 'A': -1, 'C': -2, 'B': 5, 'E': 0, 'D': 2, 'G': 0,\n","              'F': -4, 'I': -3, 'H': 1, 'K': 0, 'M': -2, 'L': -4, 'N': 7,\n","              'Q': 0, 'P': -2, 'S': 1, 'R': -1, 'T': 0, 'W': -4, 'V': -3,\n","              'Y': -2, 'X': -1, 'Z': 0},\n","        'Q': {'*': -5, 'A': -1, 'C': -3, 'B': 0, 'E': 2, 'D': 0, 'G': -2,\n","              'F': -4, 'I': -3, 'H': 1, 'K': 2, 'M': 0, 'L': -2, 'N': 0,\n","              'Q': 7, 'P': -1, 'S': 0, 'R': 1, 'T': -1, 'W': -1, 'V': -3,\n","              'Y': -1, 'X': -1, 'Z': 4},\n","        'P': {'*': -5, 'A': -1, 'C': -4, 'B': -2, 'E': -1, 'D': -1,\n","              'G': -2, 'F': -4, 'I': -3, 'H': -2, 'K': -1, 'M': -3,\n","              'L': -4, 'N': -2, 'Q': -1, 'P': 10, 'S': -1, 'R': -3,\n","              'T': -1, 'W': -4, 'V': -3, 'Y': -3, 'X': -1, 'Z': -1},\n","        'S': {'*': -5, 'A': 1, 'C': -1, 'B': 0, 'E': -1, 'D': 0, 'G': 0,\n","              'F': -3, 'I': -3, 'H': -1, 'K': 0, 'M': -2, 'L': -3, 'N': 1,\n","              'Q': 0, 'P': -1, 'S': 5, 'R': -1, 'T': 2, 'W': -4, 'V': -2,\n","              'Y': -2, 'X': -1, 'Z': 0},\n","        'R': {'*': -5, 'A': -2, 'C': -4, 'B': -1, 'E': 0, 'D': -2, 'G': -3,\n","              'F': -3, 'I': -4, 'H': 0, 'K': 3, 'M': -2, 'L': -3, 'N': -1,\n","              'Q': 1, 'P': -3, 'S': -1, 'R': 7, 'T': -1, 'W': -3, 'V': -3,\n","              'Y': -1, 'X': -1, 'Z': 0},\n","        'T': {'*': -5, 'A': 0, 'C': -1, 'B': 0, 'E': -1, 'D': -1, 'G': -2,\n","              'F': -2, 'I': -1, 'H': -2, 'K': -1, 'M': -1, 'L': -1, 'N': 0,\n","              'Q': -1, 'P': -1, 'S': 2, 'R': -1, 'T': 5, 'W': -3, 'V': 0,\n","              'Y': -2, 'X': -1, 'Z': -1},\n","        'W': {'*': -5, 'A': -3, 'C': -5, 'B': -5, 'E': -3, 'D': -5,\n","              'G': -3, 'F': 1, 'I': -3, 'H': -3, 'K': -3, 'M': -1, 'L': -2,\n","              'N': -4, 'Q': -1, 'P': -4, 'S': -4, 'R': -3, 'T': -3,\n","              'W': 15, 'V': -3, 'Y': 2, 'X': -1, 'Z': -2},\n","        'V': {'*': -5, 'A': 0, 'C': -1, 'B': -3, 'E': -3, 'D': -4, 'G': -4,\n","              'F': -1, 'I': 4, 'H': -4, 'K': -3, 'M': 1, 'L': 1, 'N': -3,\n","              'Q': -3, 'P': -3, 'S': -2, 'R': -3, 'T': 0, 'W': -3, 'V': 5,\n","              'Y': -1, 'X': -1, 'Z': -3},\n","        'Y': {'*': -5, 'A': -2, 'C': -3, 'B': -3, 'E': -2, 'D': -3,\n","              'G': -3, 'F': 4, 'I': -1, 'H': 2, 'K': -2, 'M': 0, 'L': -1,\n","              'N': -2, 'Q': -1, 'P': -3, 'S': -2, 'R': -1, 'T': -2, 'W': 2,\n","              'V': -1, 'Y': 8, 'X': -1, 'Z': -2},\n","        'X': {'*': -5, 'A': -1, 'C': -1, 'B': -1, 'E': -1, 'D': -1,\n","              'G': -1, 'F': -1, 'I': -1, 'H': -1, 'K': -1, 'M': -1,\n","              'L': -1, 'N': -1, 'Q': -1, 'P': -1, 'S': -1, 'R': -1,\n","              'T': -1, 'W': -1, 'V': -1, 'Y': -1, 'X': -1, 'Z': -1},\n","        'Z': {'*': -5, 'A': -1, 'C': -3, 'B': 1, 'E': 5, 'D': 1, 'G': -2,\n","              'F': -4, 'I': -3, 'H': 0, 'K': 1, 'M': -1, 'L': -3, 'N': 0,\n","              'Q': 4, 'P': -1, 'S': 0, 'R': 0, 'T': -1, 'W': -2, 'V': -3,\n","              'Y': -2, 'X': -1, 'Z': 5}}"],"id":"SVQHoNhF02hx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"opI7OQ2u02h3"},"outputs":[],"source":["# Import Classifier Resources\n","\n","import sys, os, pickle\n","from IPython.display import clear_output\n","from tqdm import tqdm\n","sys.path.append('/home/sj/ml/lib/python3.10/site-packages/') # *Change path as required*\n","\n","from scipy.stats import percentileofscore\n","import csv\n","\n","import numpy as np\n","import pandas as pd\n","import importlib\n","import random\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LogNorm\n","# Plots stuff\n","import matplotlib as mpl\n","from matplotlib import patches\n","from pandas.plotting import table\n","\n","import sklearn\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split, KFold\n","from skbio import DNA, Protein\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn import L1Loss\n","import copy\n","from scipy.optimize import fsolve\n","import math\n","\n","# import keras\n","# from keras.models import Sequential\n","# from keras.layers import Dense, Dropout\n","# from keras import regularizers\n","\n","def overlap_seqs(list1,list2):\n","    overlap=[]\n","    for i in range(len(list1)):\n","        if list1[i] in list2:\n","            overlap.append(list1[i])\n","    return overlap\n","\n","def flatten_list(listoflist):\n","    listoflist_fl = [];\n","    for l in range(len(listoflist)):\n","        for u in range(len(listoflist[l])):\n","            listoflist_fl.append(listoflist[l][u])\n","    return listoflist_fl\n","\n","curr_int = np.int16\n","def convert_number(seqs): # convert to numbers already aligned seqs\n","    aa = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V',  'W', 'Y','-']\n","    aadict = {aa[k]: k for k in range(len(aa))}\n","\n","    msa_num = np.array(list(map(lambda x: [aadict[y] for y in x], seqs[0:])), dtype=curr_int, order=\"c\") ### Here change ####\n","\n","    return msa_num\n","\n","def uniqueIndexes(l):\n","    seen = set()\n","    res = []\n","    for i, n in enumerate(l):\n","        if n not in seen:\n","            res.append(i)\n","            seen.add(n)\n","    return res\n","\n","def convert_letter(seqs_n): # convert to numbers already aligned seqs\n","    aa = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V',  'W', 'Y','-']\n","    aadictinv = {k: aa[k] for k in range(len(aa))}\n","    seqs=[]\n","    if type(seqs_n[0]) == curr_int:\n","        seqs.append(''.join([aadictinv[e] for e in seqs_n]))\n","    else:\n","        for t in range(len(seqs_n)):\n","            seqs.append(''.join([aadictinv[e] for e in seqs_n[t]]))\n","    return seqs\n","\n","# add some functions for independent site models\n","def loglikelihood_indip_model(fields, logZ, seqs):\n","    return fields[np.arange(len(fields)), seqs].sum(axis=1) - logZ\n","\n","def add_pseudocount(fields, n):\n","    return np.array([(f + 1/n) / np.sum((f + 1/n)) for f in fields])\n","\n","def build_model(dims, dropout_prob=0.5):\n","    assert dims[0] == A * L\n","    assert dims[-1] == 1\n","\n","    layers = [torch.nn.Flatten(), torch.nn.Linear(dims[0], dims[1])]\n","    for l in range(2, len(dims)):\n","        layers.append(torch.nn.LeakyReLU())\n","        layers.append(torch.nn.Linear(dims[l - 1], dims[l]))\n","        if l < len(dims) - 1:  # Add dropout except for the last layer\n","            layers.append(torch.nn.Dropout(p=dropout_prob))\n","    return torch.nn.Sequential(*layers)\n","\n","def getAllModels(A, L, dropout_prob=0.5):\n","    return [\n","        build_model([A * L, 1], dropout_prob), # Perceptron (Parsimonious)\n","        build_model([A * L, 2, 1], dropout_prob),\n","        build_model([A * L, 4, 1], dropout_prob),\n","        build_model([A * L, 8, 1], dropout_prob),\n","        build_model([A * L, 16, 1], dropout_prob),\n","        build_model([A * L, 32, 1], dropout_prob),\n","        build_model([A * L, 64, 1], dropout_prob),\n","        build_model([A * L, 128, 1], dropout_prob),\n","        build_model([A * L, 16, 8, 1], dropout_prob),\n","        build_model([A * L, 32, 8, 1], dropout_prob),\n","        build_model([A * L, 64, 8, 1], dropout_prob),\n","        build_model([A * L, 128, 8, 1], dropout_prob),\n","        build_model([A * L, 32, 16, 1], dropout_prob),\n","        build_model([A * L, 64, 16, 1], dropout_prob),\n","        build_model([A * L, 128, 16, 1], dropout_prob),\n","        build_model([A * L, 32, 16, 8, 1], dropout_prob),\n","        build_model([A * L, 64, 16, 8, 1], dropout_prob),\n","        build_model([A * L, 64, 32, 16, 1], dropout_prob),\n","        build_model([A * L, 128, 32, 16, 1], dropout_prob),\n","        build_model([A * L, 128, 64, 16, 1], dropout_prob),\n","        build_model([A * L, 128, 64, 32, 1], dropout_prob),\n","        build_model([A * L, 128, 64, 32, 8, 1], dropout_prob),\n","        build_model([A * L, 128, 64, 32, 16, 1], dropout_prob)]\n","\n","def getModelsBest(A, L, dropout_prob=0.5):\n","    return [\n","        build_model([A * L, 1], dropout_prob), # Perceptron (Parsimonious)\n","        build_model([A * L, 64, 1], dropout_prob)]\n","\n","def getNumInputFeatures(X_train, X_test):\n","    allLetters = ''\n","    for i in X_train:\n","        allLetters= allLetters + i\n","    for i in X_test:\n","        allLetters= allLetters + i\n","    A = len(np.unique([*allLetters]))\n","    return A\n","\n","def random9mer(num):\n","    # Define the amino acids alphabet\n","    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n","\n","    random_seqs = []\n","    # Convert the three-letter code to one-letter code (optional)\n","    for i in range(num):\n","        random_seqs.append(\"\".join(random.choice(amino_acids) for _ in range(9)))\n","    return random_seqs"],"id":"opI7OQ2u02h3"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"94-y93wr02h6","outputId":"e5e25d43-1881-4485-d975-f887c3fcf155"},"outputs":[{"name":"stdout","output_type":"stream","text":["113563 total variants.\n"]}],"source":["# Load and store SARS-CoV-2 genome and variant genomes from GISAID file\n","\n","#source for genome and hand-typed coordinates\n","#https://www.ncbi.nlm.nih.gov/nuccore/NC_045512\n","fold_out = \"Mutation Analysis/TREE_sel/\" # *Change path as required*\n","fasta_file = fold_out + \"full.fasta\" # *Download full mutations fasta file from GISAID (login and click downloads, download 'allprot' file)*\n","coordinates={\"ORF1ab\":[266,13483],\n","             \"S\":[21563,25384],\n","             \"ORF3a\":[25393,26220],\n","             \"E\":[26245,26472],\n","             \"M\":[26523,27191],\n","             \"ORF6\":[27202,27387],\n","             \"ORF7a\":[27394,27759],\n","             \"ORF7b\":[27756,27887],\n","             \"ORF8\":[27894,28259],\n","             \"N\":[28274,29533],\n","             \"ORF10\": [29558,29674]\n","             }\n","\n","# Import and store reference genome\n","\n","ref = []\n","with open(fasta_file, 'r') as fasta:\n","    for line in fasta:\n","        line = line.strip()\n","        if line.startswith('>'):\n","            accepted = False\n","            metadata = line[1:].split('|')\n","            accID = metadata[3]\n","            if accID != 'EPI_ISL_402124':\n","                break\n","            gene = metadata[0].upper()\n","            date = metadata[2]\n","            country = metadata[10]\n","            if accID and gene and date and country:\n","                ref.append([gene])\n","                accepted = True\n","        else:\n","            if accepted == True:\n","                seq = line\n","                if seq[-1] == '*':\n","                    seq = seq[0:-1]\n","                ref[-1].append(seq)\n","\n","# Create a DataFrame from the collected data\n","columns = ['gene', 'seq']\n","ref_df = pd.DataFrame(ref, columns=columns)\n","\n","# Import and store all variant sequences\n","valid_genes = ['NSP1', 'NSP2', 'NSP3', 'NSP4', 'NSP5', 'NSP6', 'NSP7', 'NSP8', 'NSP9',\n","                  'NSP10', 'NSP11', 'NSP12', 'NSP13', 'NSP14', 'NSP15', 'NSP16', 'SPIKE',\n","                  'NS3', 'E', 'M', 'NS6', 'NS7A', 'NS7B', 'NS8', 'N', 'NS9B', 'NS9C']\n","\n","valid_passages = ['original', 'orginal', 'orignal']\n","def is_valid_metadata(metadata):\n","    if len(metadata) != 11:\n","        return False\n","\n","    gene = metadata[0].upper()\n","    if gene not in valid_genes:\n","        return False\n","\n","    date = metadata[2]\n","    dates = date.split('-')\n","    if dates[0][0:2] != '20' or int(dates[1]) < 1 or int(dates[2]) < 1:\n","        return False\n","\n","    accID = metadata[3].upper()\n","    if accID == 'EPI_ISL_402124':\n","        return False\n","\n","    passage = metadata[4].lower()\n","    if passage not in valid_passages:\n","        return False\n","\n","    animal = metadata[6].lower()\n","    if animal != 'human':\n","        return False\n","\n","    return True\n","\n","data = []\n","i = 0\n","labs = []\n","with open(fasta_file, 'r') as fasta:\n","    accID = ''\n","    gene = ''\n","    date = ''\n","    country = ''\n","\n","    for line in fasta:\n","        line = line.strip()\n","        if line.startswith('>'):\n","            accepted = False\n","            metadata = line[1:].split('|')\n","            if is_valid_metadata(metadata):\n","                accID = metadata[3]\n","                gene = metadata[0].upper()\n","                date = metadata[2]\n","                country = metadata[10]\n","                if '\\S' in metadata[-3]:\n","                    lab = metadata[-3]\n","                else:\n","                    lab = codecs.decode(metadata[-3], 'unicode_escape')\n","                if accID and gene and date and country:\n","                    data.append([accID, gene, date, country, lab])\n","                    accepted = True\n","                    i += 1\n","        else:\n","            if accepted == True:\n","                seq = line\n","                if seq[-1] == '*':\n","                    seq = seq[0:-1]\n","                data[-1].append(seq)\n","\n","# Create a DataFrame from the collected data\n","columns = ['accID', 'gene', 'date', 'country', 'lab', 'seq']\n","var_df = pd.DataFrame(data, columns=columns)\n","\n","# Remove rows from var_df where accID count is not equal to 27 - small proportion ~0.1%\n","accIDs = var_df['accID']\n","countsOfAccIDs = Counter(accIDs)\n","var_df = var_df[var_df['accID'].map(lambda x: countsOfAccIDs[x]) == 27]\n","\n","print(int(len(var_df)/27), 'total variants.')"],"id":"94-y93wr02h6"},{"cell_type":"code","source":["# Load and store PRIME epitopes, and convert to sort by NSP\n","\n","epitopes = {}\n","# Experimentally verified PRIME epitopes\n","# epitopes['ORF3A'] = ['LYLYALVYF', 'FTSDYYQLY', 'LPFGWLIV', 'SASKIITLK', 'QSASKIITLK']\n","# epitopes['N'] = ['DLSPRWYFYY', 'LSPRWYFYY']\n","# epitopes['ORF1AB'] = ['EYADVFHLYL']\n","# epitopes['S'] = ['ECSNLLLQY', 'LPPAYTNSF', 'QYIKWPWYIW', 'YFPLQSYGF']\n","# epitopes['E'] = ['YFIASFRLF', 'LWLLWPVTL', 'QWNLVIGFLF', 'RFLYIIKLI', 'NRNRFLYII', 'ATSRTLSYYK']\n","# epitopes['M'] = ['YFIASFRLF', 'LWLLWPVTL', 'QWNLVIGFLF', 'RFLYIIKLI', 'NRNRFLYII', 'ATSRTLSYYK']\n","\n","# All PRIME epitopes\n","epitopes['SPIKE'] = ['CNDPFLGVYY','STECSNLLLQY','CVADYSVLY','NIDGYFKIY','ECSNLLLQY','TSNQVAVLY','VADYSVLY','KIADYNYKL','RLQSLQTYV','YLQPRTFLL','VLNDILSRL','KLNDLCFTNV','RLNEVAKNL','TLDSKTQSL','ALNTLVKQL','SIIAYTMSL','RLDKVEAEV','NLNESLIDL','KLQDVVNQN','LLFNKVTLA','HLMSFPQSA','LITGRLQSL','FIAGLIAIV','GVYFASTEK','SVYAWNRKR','AQALNTLVK','GVYYHKNNK','SVLNDILSR','TLKSFTVEK','ASANLAATK','KSTNLVKNK','GSFCTQLNR','VVLSFELLH','YLQPRTFLLK','GTHWFVTQR','ASVYAWNRK','STGSNVFQT','NSASFSTFK','ASFSTFKCY','QYIKWPWYI','NYNYLYRLF','QYIKWPWYIW','PYRVVVLSF','SPRRARSVA','QPYRVVVLSF','GPKKSTNLV','SLSSTASAL','TPTWRVYST','YQPYRVVVL','LLFNKVTL','INITRFQTL','LVKNKCVNF','DLLFNKVTL','FNATRFASV','FKNLREFVF','LPFNDGVYF','LPFFSNVTW','QPRTFLLKY','LPPAYTNSF','GVVFLHVTY','DPFLGVYY','TEKSNIIRGW','ADAGFIKQY','SETKCTLKSF','EELDKYFKNH','TECSNLLLQY','QEVFAQVKQI','IPTNFTISV','HGVVFLHV','IAIVMVTI','LPLVSSQCV','QPYRVVVL','NATNVVIKV','VVFLHVTYV','TQDLFLPFF','RFDNPVLPF','YFPLQSYGF','LTDEMIAQY','IEDLLFNKV','TTEILPVSM','IADYNYKL','SAPHGVVFL','STECSNLLL','IKDFGGFNF','VRFPNITNL','TRFQTLLAL','FRSSVLHST','GNYNYLYRL','YRVVVLSF','VVFLHVTY','TRFASVYAW','YYPDKVFRS']\n","epitopes['ORF3a'] = ['FTSDYYQLY','FLCWHTNCY','HSYFTSDYY','TSDYYQLY','GLEAPFLYLY','FLYLYALVY','YLYALVYFL','LLYDANYFL','ALSKGVHFV','TVYSHLLLV','ALLAVFQSA','SASKIITLK','FTIGTVTLK','KRWQLALSK','QSASKIITLK','ASKIITLKK','HVTFFIYNK','ATATIPIQA','LYLYALVYF','YYQLYSTQL','HFVCNLLLL','YFTSDYYQL','LFVTVYSHL','APFLYLYAL','DLFMRIFTI','QSASKIITL','TLKKRWQL','TLKKRWQLA','NPLLYDANY','LLLLFVTVY','LEAPFLYLY','EEHVQIHTI','SEHDYQIGGY','LPFGWLIV','LYDANYFL','QSINFVRII','CRSKNPLLY','KGVHFVCNL','VEHVTFFIY']\n","epitopes['E'] = ['FLAFVVFLL','SLVKPSFYV','LFLAFVVFL','VFLLVTLAI','YVYSRVKNL','FVVFLLVTL','LAFVVFLLV','LAFVVFLL','IVNSVLLFL','LVKPSFYVY','VKPSFYVY']\n","epitopes['M'] = ['ATSRTLSYY','SSDNIALLV','LVGLMWLSY','VATSRTLSY','TVATSRTLSY','TVATSRTLSYY','KLLEQWNLV','TLACFVLAA','FLYIIKLIFL','TLACFVLAAV','FVLAAVYRI','ATSRTLSYYK','LVIGAVILR','LFLTWICLL','LYIIKLIFL','LWLLWPVTL','QWNLVIGFLF','YFIASFRLF','LYIIKLIFLW','SYFIASFRL','RFLYIIKLI','LPKEITVAT','IIKLIFLWL','LEQWNLVIGF','EELKKLLEQW','LWPVTLACF','SSDNIALL','QWNLVIGFL','NRFLYIIKL','SSSDNIALL','SRTLSYYKL','NRNRFLYII','ARTRSMWSF']\n","epitopes['N'] = ['DLSPRWYFYY','LSPRWYFYY','DLSPRWYFY','VTPSGTWLTY','LLLDRLNQL','LQLPQGTTL','NFKDQVILL','SPRWYFYYL','GPQNQRNAP','TPSGTWLTY','MEVTPSGTW','DAALALLL','DAALALLLL','NAAIVLQL','NNAAIVLQL']\n","epitopes['ORF1ab'] = ['YSVIYLYLTFY','YADVFHLY','YADVFHLYL','DVFHLYLQY','NQEYADVFHLY','YADVFHLYLQY','WLMWLIINL','SLPGVFCGV','TLMNVLTLV','SMWALIISV','GVYSVIYLY','VYSVIYLYL','IYLYLTFYL','VYSVIYLYLTF','EYADVFHLY','VFHLYLQYI','EYADVFHLYL','LPGVYSVIY','HPNQEYADVF','QEYADVFHL','QEYADVFHLY','LPGVYSVI','VYSVIYLY']\n","\n","prime_epitopes = {}\n","# Iterate over each gene in ref_df\n","for index, row in ref_df.iterrows():\n","    gene_name = row['gene']\n","    gene_sequence = row['seq']\n","    found_epitopes = [] # Initialise a list to store epitopes found in each gene\n","    # Iterate over each epitope in epitopes\n","    for epitope_gene, epitope_list in epitopes.items():\n","        # Search for epitope sequence within gene sequence\n","        for epitope in epitope_list:\n","            if epitope in gene_sequence:\n","                found_epitopes.append(epitope)\n","    # Store the found epitopes in prime_epitopes dictionary\n","    if len(found_epitopes) > 0:\n","        prime_epitopes[gene_name] = found_epitopes"],"metadata":{"id":"F2-hOqBO3ftd"},"id":"F2-hOqBO3ftd","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9cgoH4R02h9"},"outputs":[],"source":["# Functions for mutation detection\n","\n","def getSeqAligned(epitope, sequence):\n","    \"\"\"\n","    Retrieves the aligned sequence from a local pairwise alignment between an epitope and a larger sequence.\n","\n","    Parameters:\n","    epitope (str): The epitope sequence.\n","    sequence (str): The larger sequence containing the epitope.\n","\n","    Returns:\n","    str: The aligned sequence containing the epitope.\n","\n","    \"\"\"\n","    # Create BioPython Seq objects from the input strings\n","    epitope_prot = Protein(epitope)\n","    sequence_prot = Protein(sequence)\n","\n","    # Perform local pairwise alignment using Smith-Waterman algorithm with a substitution matrix (blosum50)\n","    alignment = local_pairwise_align_ssw(epitope_prot, sequence_prot, substitution_matrix=blosum50)[2][1]\n","\n","    # Extract the aligned sequence containing the epitope based on the alignment indices\n","    return sequence[alignment[0]:alignment[1]+1]\n","\n","def getMutationType(seq1, seq2, subOnly=0):\n","    \"\"\"\n","    Determines the type of mutation between two sequences and returns relevant information.\n","\n","    Args:\n","        seq1 (str): The first sequence.\n","        seq2 (str): The second sequence.\n","        subOnly (int) = (default value = 0) Value to represent if all mutation types are checked, or just substitution.\n","\n","    Returns:\n","        tuple: A tuple containing the mutation type and additional information:\n","            - If the sequences are the same, returns ('-1',)\n","            - If there is a substitution, returns ('substitution', mutation_positions), where mutation_positions is an array\n","              of lists containing the mutated positions and their corresponding residues before and after the mutation.\n","            - If there is an insertion, returns ('insertion', [inserted_seq, position]), where inserted_seq is the inserted\n","              sequence and position is the position in seq1 where the insertion occurred.\n","            - If there is a deletion, returns ('deletion', -1).\n","            - If no mutation is detected or an unsupported case is encountered, returns ('-1',).\n","\n","    \"\"\"\n","    if seq1 == seq2:\n","        # If the sequences are the same, then return -1\n","        return -1\n","    elif len(seq2) == len(seq1):\n","        mutation_positions = []\n","        for i in range(len(seq1)):\n","            residue1, residue2 = seq1[i], seq2[i]\n","            if residue1 != residue2:\n","                mutation_positions.append([i+1, residue1, residue2])\n","        if len(mutation_positions) > 0:\n","            # Return mutation type, and an array of the mutated positions, and their residues pre- and post-mutation\n","            return 'substitution', mutation_positions\n","    elif len(seq2) > len(seq1) and subOnly == 0:\n","        if seq1[0] == seq2[0] and seq1[-1] == seq2[-1]:\n","            if seq2[:-1] == seq1:\n","                return 'insertion', [seq2[-1],len(seq1)-1]\n","            if seq1[1:] == seq1:\n","                return 'insertion', [seq2[0],1]\n","            for i in range(len(seq1)):\n","                try:\n","                    seq1[i] != seq2[i]\n","                except IndexError as e:\n","                    return 'insertion', -1\n","                if seq1[i] != seq2[i]:\n","                    inserted_seq = seq2[i:i+len(seq2)-len(seq1)]\n","                    if seq1[i:] == seq2[i+len(inserted_seq):] and inserted_seq != '': # If ends match and no error\n","                        # Return mutation type, and a tuple of the inserted sequence and the position in seq1 in which it was inserted into\n","                        return 'insertion', [inserted_seq,i]\n","                    else:\n","                        # If no simple insertion, return mutation type, and -1\n","                        return 'insertion', -1\n","        else:\n","            # If no simple insertion, return mutation type, and -1\n","            return 'insertion', -1\n","    elif len(seq2) < len(seq1) and subOnly == 0:\n","        if seq1[0] == seq2[0] and seq1[-1] == seq2[-1]:\n","            if seq1[:-1] == seq2:\n","                return 'deletion', [seq1[-1],len(seq2)-1]\n","            if seq1[1:] == seq2:\n","                return 'deletion', [seq1[0],1]\n","            for i in range(len(seq1)):\n","                try:\n","                    seq1[i] != seq2[i]\n","                except IndexError as e:\n","                    return 'deletion', -1\n","                if seq1[i] != seq2[i]:\n","                    deleted_seq = seq1[i:i+len(seq1)-len(seq2)]\n","                    if seq2[i:] == seq1[i+len(deleted_seq):] and deleted_seq != '': # If ends match and no error\n","                        # Return mutation type, and a tuple of the inserted sequence and the position in seq1 in which it was inserted into\n","                        return 'deletion', [deleted_seq,i]\n","                    else:\n","                        # If no simple insertion, return mutation type, and -1\n","                        return 'deletion', -1\n","        else:\n","            # If no simple deletion, return mutation type, and -1\n","            return 'deletion', -1\n","    else:\n","        return -1\n","\n","# *Use below if data is saved to file (to save having to repeat analysis each time)*\n","# mutations_detected = np.load('temp/IEDB_peptides_with_mutations.npy')"],"id":"j9cgoH4R02h9"},{"cell_type":"code","source":["# # Load mutation_rows if saved file\n","# with open('temp/mutation_rows.pkl', 'rb') as file:\n","#     mutation_rows = pickle.load(file)"],"metadata":{"id":"VMdB0GBC30gX"},"id":"VMdB0GBC30gX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Get all epitopes and mutations - to use with PRIME2.0 server\n","\n","# epi, mut = [], []\n","# for gene in mutation_rows.keys():\n","#     for epitope in mutation_rows[gene]:\n","#         epi.append(epitope['epitope'])\n","#         m = epitope['mutation']\n","#         if 'X' not in m and len(m) >= 8 and len(m) <= 14:\n","#             mut.append(m)\n","# epi, mut = np.unique(np.array(epi)), np.unique(np.array(mut))\n","\n","# with open('epitopes_all.txt', 'w') as epitopes_file:\n","#     for epitope in epi:\n","#         epitopes_file.write(epitope + '\\n')\n","\n","# with open('mutations_all.txt', 'w') as mutations_file:\n","#     for mutation in mut:\n","#         mutations_file.write(mutation + '\\n')\n","\n","# Steps in between:\n","#     Go to http://prime.gfellerlab.org/\n","#     Alleles = A0101,A2501,B0801,B1801,C0702,A0201,A0301,A1101,A2402,A2601,B0702,B0801,B3501,B4402,B5101,C0401,C0501,C0602,C0701,C0702\n","#     Calculate PRIME2.0 scores on both epitopes_all.txt and mutations_all.txt files.\n","#     For both downloaded files, open in Excel\n","#     Delete commented out rows, so first row is table headers.\n","#     Delete columns after BestAllele.\n","#     Save, and run code below\n","\n","\n","# Load in scores calculated from PRIME2.0 server\n","\n","epitopes_prime_scores = {}\n","with open('epitopes_all_res.txt', 'r') as file:\n","    header = next(file)\n","    for line in file:\n","        line = line.strip()\n","        values = line.split(',')\n","        epitope = values[0]\n","        scores = {\n","            '%Rank_bestAllele': values[1],\n","            'Score_bestAllele': values[2],\n","            '%RankBinding_bestAllele': values[3],\n","            'BestAllele': values[4]\n","        }\n","        epitopes_prime_scores[epitope] = scores\n","\n","mutations_prime_scores = {}\n","with open('mutations_all_res.txt', 'r') as file:\n","    header = next(file)\n","    for line in file:\n","        line = line.strip()\n","        values = line.split(',')\n","        mutation = values[0]\n","        scores = {\n","            '%Rank_bestAllele': values[1],\n","            'Score_bestAllele': values[2],\n","            '%RankBinding_bestAllele': values[3],\n","            'BestAllele': values[4]\n","        }\n","        mutations_prime_scores[mutation] = scores"],"metadata":{"id":"MLkEBuvz5TXH","executionInfo":{"status":"ok","timestamp":1699798786698,"user_tz":0,"elapsed":293,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"id":"MLkEBuvz5TXH","execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joxrRMPU02h_"},"outputs":[],"source":["# Save/Load IEDB Data\n","\n","range_len = [8, 9, 10, 11]\n","list_hlas = ['HLA-A*01:01', 'HLA-A*02:01', 'HLA-A*03:01', 'HLA-A*11:01', 'HLA-A*24:02', 'HLA-B*07:02', 'HLA-B*08:01', 'HLA-B*15:01', 'HLA-B*35:01', 'HLA-B*40:01'] # 10 most frequent HLAs used\n","A,L=20,9\n","\n","# # Save the variables, dictionaries, and arrays to a file\n","# with open('data.pkl', 'wb') as file:\n","#     data = {\n","#         'pep_dict_train': pep_dict_train,\n","#         'pepsP_train': pepsP_train,\n","#         'pepsN_train': pepsN_train,\n","#         'pep_dict_test': pep_dict_test,\n","#         'pepsP_test': pepsP_test,\n","#         'pepsN_test': pepsN_test\n","#     }\n","#     pickle.dump(data, file)\n","\n","# Load the variables, dictionaries, and arrays from the file\n","with open('Classifier/Data/iedb_data.pkl', 'rb') as file:\n","    data = pickle.load(file)\n","    pep_dict_train = data['pep_dict_train']\n","    pepsP_train = data['pepsP_train']\n","    pepsN_train = data['pepsN_train']\n","    pep_dict_test = data['pep_dict_test']\n","    pepsP_test = data['pepsP_test']\n","    pepsN_test = data['pepsN_test']\n","\n","def getSplitData(pepsP_train, pepsN_train, pepsP_test, pepsN_test, split=0.25):\n","\n","    hlaP_train, hlaN_train, hlaP_test, hlaN_test = [], [], [], []\n","\n","    for alleles in range(len(list_hlas)):\n","        hlaP_train.append([list_hlas[alleles]] * len(pepsP_train[alleles]))\n","        hlaN_train.append([list_hlas[alleles]] * len(pepsN_train[alleles]))\n","        hlaP_test.append([list_hlas[alleles]] * len(pepsP_test[alleles]))\n","        hlaN_test.append([list_hlas[alleles]] * len(pepsN_test[alleles]))\n","\n","    # Concatenate positive and negative peptides for each allele\n","    pepsP_train_concat = np.concatenate(pepsP_train)\n","    pepsN_train_concat = np.concatenate(pepsN_train)\n","    pepsP_test_concat = np.concatenate(pepsP_test)\n","    pepsN_test_concat = np.concatenate(pepsN_test)\n","\n","    # Concatenate HLA labels for each peptide\n","    hlaP_train_concat = np.concatenate(hlaP_train)\n","    hlaN_train_concat = np.concatenate(hlaN_train)\n","    hlaP_test_concat = np.concatenate(hlaP_test)\n","    hlaN_test_concat = np.concatenate(hlaN_test)\n","\n","    Ptest_cutoff = int(split*len(pepsP_test_concat))\n","    Ntest_cutoff = int(split*len(pepsN_test_concat))\n","\n","    # Create X_train by combining non-SARS-CoV-2 data with 25% of SARS-CoV-2 data from pepsP_test and pepsN_test\n","    X_train = np.concatenate([pepsP_train_concat, pepsN_train_concat, pepsP_test_concat[:Ptest_cutoff], pepsN_test_concat[:Ntest_cutoff]])\n","    X_test = np.concatenate([pepsP_test_concat[Ptest_cutoff:], pepsN_test_concat[Ntest_cutoff:]])\n","\n","    # Create y_train by assigning 1 to immunogenic peptides and 0 to non-immunogenic peptides\n","    y_train = np.concatenate([np.ones(len(pepsP_train_concat)), np.zeros(len(pepsN_train_concat)), np.ones(Ptest_cutoff), np.zeros(Ntest_cutoff)])\n","    y_test = np.concatenate([np.ones(len(pepsP_test_concat[Ptest_cutoff:])), np.zeros(len(pepsN_test_concat[Ntest_cutoff:]))])\n","\n","    # Create hla_train, hla_test\n","    hla_train = np.concatenate([hlaP_train_concat, hlaN_train_concat, hlaP_test_concat[:Ptest_cutoff], hlaN_test_concat[:Ntest_cutoff]])\n","    hla_test = np.concatenate([hlaP_test_concat[Ptest_cutoff:], hlaN_test_concat[Ntest_cutoff:]])\n","\n","    # Shuffle the data\n","    random_indices_train = np.random.permutation(len(X_train))\n","    random_indices_test = np.random.permutation(len(X_test))\n","\n","    X_train = X_train[random_indices_train]\n","    hla_train = hla_train[random_indices_train]\n","    y_train = y_train[random_indices_train]\n","\n","    X_test = X_test[random_indices_test]\n","    hla_test = hla_test[random_indices_test]\n","    y_test = y_test[random_indices_test]\n","\n","    return X_train, y_train, hla_train, X_test, y_test, hla_test\n","\n","def getSplitDataHLA(HLA, split=0.25):\n","    # (For single allele classifier)\n","    p_train, n_train, p_test, n_test = pep_dict_train[HLA][0], pep_dict_train[HLA][1], pep_dict_test[HLA][0], pep_dict_test[HLA][1]\n","\n","    Ptest_cutoff = int(split*len(p_test))\n","    Ntest_cutoff = int(split*len(n_test))\n","\n","    # Create X_train by combining non-sars-cov-2 data with 25% of sars-cov-2 data from pepsP_test and pepsN_test\n","    X_train = np.concatenate([p_train, n_train, p_test[:Ptest_cutoff], n_test[:Ntest_cutoff]])\n","    X_test = np.concatenate([p_test[Ptest_cutoff:], n_test[Ntest_cutoff:]])\n","\n","    # Create y_train by assigning 1 to immunogenic peptides and 0 to non-immunogenic peptides\n","    y_train = np.concatenate([np.ones(len(p_train)), np.zeros(len(n_train)), np.ones(Ptest_cutoff), np.zeros(Ntest_cutoff)])\n","    y_test = np.concatenate([np.ones(len(p_test[Ptest_cutoff:])), np.zeros(len(n_test[Ntest_cutoff:]))])\n","\n","    # Shuffle the data\n","    random_indices_train = np.random.permutation(len(X_train))\n","    random_indices_test = np.random.permutation(len(X_test))\n","    X_train = X_train[random_indices_train]\n","    y_train = y_train[random_indices_train]\n","    X_test = X_test[random_indices_test]\n","    y_test = y_test[random_indices_test]\n","\n","    return X_train, y_train, X_test, y_test\n","\n","def getPeptideGene(peptide):\n","    for geneName in ref_df['gene']:\n","        if peptide in ref_df[ref_df['gene'] == geneName]['seq'].values[0]:\n","            return geneName\n","    return -1\n","\n","model = copy.deepcopy(getAllModels(A, L)[7]) #*Change model as required*\n","random_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number(random9mer(1000000))), num_classes=A).type(torch.FloatTensor)\n","random_scores = np.squeeze(model(random_tensor).detach().numpy())\n","\n","def percentile_rank(X_scores):\n","    # Calculate the percentile rank of X_scores with respect to random_scores\n","    X_ranks = [100 * np.sum(random_scores > score) / len(random_scores) for score in X_scores]\n","    return X_ranks"],"id":"joxrRMPU02h_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyTnIQQF02iA"},"outputs":[],"source":["# Organise all IEDB SARS-CoV-2 reference genome genes\n","\n","X_train, y_train, hla_train, X_test, y_test, hla_test = getSplitData(pepsP_train, pepsN_train, pepsP_test, pepsN_test)\n","X = np.array(list(X_train) + list(X_test))\n","y = np.array(list(y_train) + list(y_test))\n","hla = np.array(list(hla_train) + list(hla_test))\n","X_ref_by_gene, y_ref_by_gene, hla_ref_by_gene, auc_by_gene, all_X_gene = {}, {}, {}, {}, []\n","for geneName in ref_df['gene']:\n","    X_ref_by_gene[geneName], y_ref_by_gene[geneName], hla_ref_by_gene[geneName], auc_by_gene[geneName] = [], [], [], []\n","for i in range(len(X)):\n","    geneName = getPeptideGene(X[i])\n","    if geneName != -1:\n","        all_X_gene.append(geneName)\n","        X_ref_by_gene[geneName].append(X[i])\n","        y_ref_by_gene[geneName].append(y[i])\n","        hla_ref_by_gene[geneName].append(hla[i])\n","    else:\n","        all_X_gene.append('Unknown')"],"id":"NyTnIQQF02iA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nB2b14u02iC"},"outputs":[],"source":["# *Use below if data/models are saved to files*\n","def getComparisonDF(model1, model2):\n","    classifiers = getAllModels(A, L)\n","    X_train, y_train, _, X_test, y_test, _ = getSplitData(pepsP_train, pepsN_train, pepsP_test, pepsN_test)\n","    X = np.array(list(X_train) + list(X_test))\n","    X_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number(X)), num_classes=A).type(torch.FloatTensor)\n","    y = np.array(list(y_train) + list(y_test))\n","    X_ref_by_gene, y_ref_by_gene, hla_ref_by_gene, auc_by_gene, all_X_gene, mutation_exists = {}, {}, {}, {}, [], []\n","    for pep in X:\n","        geneName = getPeptideGene(pep)\n","        if geneName != -1:\n","            all_X_gene.append(geneName)\n","        else:\n","            all_X_gene.append('Unknown')\n","        if pep in mutations_detected:\n","            mutation_exists.append(True)\n","        else:\n","            mutation_exists.append(False)\n","    scores, ranks, preds = [], [], []\n","    for model_name in [model1, model2]:\n","        if model_name == 'PRIME2.0':\n","            scores.append(np.loadtxt('prime_X_scores'))\n","            ranks.append(np.loadtxt('prime_X_ranks'))\n","        else:\n","            if model_name == 'prtr-pars':\n","                model = copy.deepcopy(classifiers[0])\n","            elif model_name == 'prtr-deep':\n","                model = copy.deepcopy(classifiers[6])\n","            elif model_name == 'parsimonious':\n","                model = copy.deepcopy(classifiers[0])\n","            elif model_name == 'deep':\n","                model = copy.deepcopy(classifiers[7])\n","            else:\n","                print('Model unrecognised')\n","                break\n","            # Get model results on test data X\n","            model.load_state_dict(torch.load('Classifier/Models/' + model_name + '.pth')) # *Change path as required*\n","            current_scores = np.squeeze(model(X_tensor).detach().numpy())\n","            scores.append(current_scores)\n","            ranks.append(percentile_rank(current_scores))\n","\n","    # Get immunogenic predictions, y_pred, from PRIME and deep classifier\n","    preds = [[], []]\n","    model_num = 0\n","    for model_name in [model1, model2]:\n","        if model_name == 'PRIME':\n","            threshold = 0.5\n","        else:\n","            threshold = 5\n","        for rank in ranks[model_num]:\n","            if rank <= threshold:\n","                preds[model_num].append(1)\n","            else:\n","                preds[model_num].append(0)\n","        model_num += 1\n","\n","    # Put all PRIME and deep classifier data into dataframe\n","    overlap_df = pd.DataFrame({\n","        'X': X,\n","        'y': y,\n","        'gene': all_X_gene,\n","        'mutation_exists': mutation_exists,\n","        'model_1_scores': scores[0],\n","        'model_2_scores': scores[1],\n","        'model_1_ranks': ranks[0],\n","        'model_2_ranks': ranks[1],\n","        'model_1_pred': preds[0],\n","        'model_2_pred': preds[1]\n","    })\n","    return overlap_df"],"id":"7nB2b14u02iC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HTYKCbsj02iE"},"outputs":[],"source":["def allOverlapPlots(overlap_dic, name_X, name_y):\n","    scores_X, scores_y, ranks_X, ranks_y, pred_X, pred_y = overlap_df['model_1_scores'], overlap_df['model_2_scores'], overlap_df['model_1_ranks'], overlap_df['model_2_ranks'], overlap_df['model_1_pred'], overlap_df['model_2_pred']\n","    plt.scatter(scores_X, scores_y, marker='x', s=9, alpha = 0.5)\n","    plt.title(name_X + ' vs ' + name_y + ' Immunogenicity Prediction Scores')\n","    plt.xlabel(name_X + ' Classifier Scores')\n","    plt.ylabel(name_y + ' Classifier Scores')\n","    plt.show();\n","\n","    # Scores Hexbin\n","    plt.hexbin(scores_X, scores_y, gridsize=20, cmap='Blues')\n","    plt.xlabel(name_X + ' Classifier Scores')\n","    plt.ylabel(name_y + ' Classifier Scores')\n","    plt.title('Hexbin Plot of Immunogenicity Prediction Scores')\n","    plt.colorbar(label='Count')\n","    plt.show();\n","\n","    # Scores Histogram\n","    plt.hist(scores_X, histtype='step', bins=50, label= name_X + ' Classifier Scores')\n","    plt.hist(scores_y, histtype='step', bins=50, label= name_y + ' Classifier Scores')\n","    plt.xlabel('Immunogenicity Prediction Scores')\n","    plt.ylabel('Count')\n","    plt.title('Histogram of ' + name_X + ' vs ' + name_y + ' Classifier Immunogenicity Prediction Scores')\n","    plt.legend()\n","    plt.show();\n","\n","    # Scores KDE Plot\n","    sns.kdeplot(scores_X, label= name_X + ' Classifier Scores', fill=True)\n","    sns.kdeplot(scores_y, label= name_y + ' Classifier Scores', fill=True)\n","    plt.xlabel('Immunogenicity Prediction Scores')\n","    plt.ylabel('Density')\n","    plt.title('KDE Plot of ' + name_X + ' vs ' + name_y + ' Classifier Immunogenicity Prediction Scores')\n","    plt.legend()\n","    plt.show();\n","\n","    # Scatter Ranks\n","    plt.scatter(ranks_X, ranks_y, marker='x', s=9, alpha = 0.5)\n","    plt.title(name_X + ' vs ' + name_y + ' Classifier Immunogenicity Prediction %Ranks')\n","    plt.xlabel(name_X + ' %Rank Score')\n","    plt.ylabel(name_y + ' Classifier %Rank Score')\n","    plt.show();\n","\n","    # Ranks Hexbin\n","    plt.hexbin(ranks_X, ranks_y, gridsize=20, cmap='Blues')\n","    plt.xlabel(name_X + ' Classifier %Rank Scores')\n","    plt.ylabel(name_y + ' Classifier %Rank Scores')\n","    plt.title('Hexbin Plot of Immunogenicity Prediction %Rank Scores')\n","    plt.colorbar(label='Count')\n","    plt.show()\n","\n","    # Ranks Histogram\n","    plt.hist(ranks_X, histtype='step', bins=50, label=name_X + ' Classifier Scores')\n","    plt.hist(ranks_y, histtype='step', bins=50, label=name_y + ' Classifier Scores')\n","    plt.xlabel('Immunogenicity Prediction %Rank Scores')\n","    plt.ylabel('Count')\n","    plt.title('Histogram of ' + name_X + ' vs ' + name_y + ' Classifier Immunogenicity Prediction %Ranks')\n","    plt.legend()\n","    plt.show();\n","\n","    # Ranks KDE Plot\n","    sns.kdeplot(ranks_X, label=name_X + ' Classifier Scores', fill=True)\n","    sns.kdeplot(ranks_y, label=name_y + ' Classifier Scores', fill=True)\n","    plt.xlabel('Immunogenicity Prediction %Rank Scores')\n","    plt.ylabel('Density')\n","    plt.title('KDE Plot of ' + name_X + ' vs ' + name_y + ' Classifier Immunogenicity Prediction %Ranks')\n","    plt.legend()\n","    plt.show();\n","\n","    print(f\"Correlation Coefficient (Scores): {np.corrcoef(scores_X, scores_y)[0, 1]}\")\n","    print(f\"Correlation Coefficient (Ranks): {np.corrcoef(ranks_X, ranks_y)[0, 1]}\")"],"id":"HTYKCbsj02iE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9eUY_6S02iG"},"outputs":[],"source":["def mainOverlapPlots(overlap_df, name_X, name_y, unknown_gene_visible = True, mutations_visible = False):\n","    if unknown_gene_visible:\n","        gene_palette = sns.color_palette('hsv', n_colors=27)\n","    else:\n","        overlap_df = overlap_df[overlap_df['gene'] != 'Unknown']\n","        gene_palette = sns.color_palette('hsv', n_colors=26)\n","    X, y, mutation_exists, scores_X, scores_y, ranks_X, ranks_y, pred_X, pred_y = overlap_df['X'], overlap_df['y'], overlap_df['mutation_exists'], overlap_df['model_1_scores'], overlap_df['model_2_scores'], overlap_df['model_1_ranks'], overlap_df['model_2_ranks'], overlap_df['model_1_pred'], overlap_df['model_2_pred']\n","    print(f\"Correlation Coefficient (Scores): {round(np.corrcoef(scores_X, scores_y)[0, 1],4)}\")\n","    print(f\"Correlation Coefficient (Ranks): {round(np.corrcoef(ranks_X, ranks_y)[0, 1],4)}\")\n","    # Create the Marginal Histogram of %Rank Scores\n","    joint_plot = sns.jointplot(data=overlap_df, x=\"model_1_ranks\", y=\"model_2_ranks\", space=0, hue='gene', palette=gene_palette, xlim=(-max(ranks_X)*0.1, max(ranks_X)*1.1), ylim=(-max(ranks_y)*0.1, max(ranks_y)*1.1), height=6, ratio=5, edgecolor='None')\n","    joint_plot.set_axis_labels(name_X + ' Classifier Immunogenicity %Rank Scores', name_y + ' Classifier Immunogenicity %Rank Scores')\n","    if mutations_visible:\n","        mutation_exists_points = overlap_df[mutation_exists]\n","        plt.scatter(mutation_exists_points['model_1_ranks'], mutation_exists_points['model_2_ranks'], facecolors='none', edgecolors='black', linewidths=0.5, s=30, label='Peptides w/\\n Mutations')\n","    plt.legend(title='Gene', loc='center left', bbox_to_anchor=(1.25, 0.5), fontsize=9)\n","    plt.suptitle(name_X + ' vs ' + name_y + ' Classifier %Rank Scores Marginal Histogram by Gene', y=1.02)\n","    plt.savefig('Classifier/Images/z.' + name_X + ' vs ' + name_y + ' Classifier %Rank Scores Marginal Histogram.png')\n","    plt.show();\n","\n","    # Calculate ROC curve and AUC for Prime model\n","    fpr_1, tpr_1, thresholds_1 = roc_curve(y, pred_X)\n","    roc_auc_1 = auc(fpr_1, tpr_1)\n","    # Calculate PR curve and AUCPR for Prime model\n","    precision_1, recall_1, thresholds_1_pr = precision_recall_curve(y, pred_X)\n","    pr_auc_1 = average_precision_score(y, pred_X)\n","    # Calculate ROC curve and AUC for Deep model\n","    fpr_2, tpr_2, thresholds_2 = roc_curve(y, pred_y)\n","    roc_auc_2 = auc(fpr_2, tpr_2)\n","    # Calculate PR curve and AUCPR for Deep model\n","    precision_2, recall_2, thresholds_2_pr = precision_recall_curve(y, pred_y)\n","    pr_auc_2 = average_precision_score(y, pred_y)\n","\n","    # Create a figure with two subplots side by side\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n","    # Plot ROC curves in the first subplot\n","    plt.sca(axes[0])\n","    plt.plot(fpr_1, tpr_1, color='orange', lw=2, label=name_X + ' Model (AUC = {:.2f})'.format(roc_auc_1))\n","    plt.plot(fpr_2, tpr_2, color='blue', lw=2, label=name_y + ' Model (AUC = {:.2f})'.format(roc_auc_2))\n","    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    # Plot PR curves in the second subplot\n","    plt.sca(axes[1])\n","    plt.plot(recall_1, precision_1, color='orange', lw=2, label=name_X + ' Model (AUCPR = {:.2f})'.format(pr_auc_1))\n","    plt.plot(recall_2, precision_2, color='blue', lw=2, label=name_y + ' Model (AUCPR = {:.2f})'.format(pr_auc_2))\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall (PR) Curve')\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.savefig('Classifier/Images/z.' + name_X + ' vs ' + name_y + ' Classifier AUC & AUCPR Plots.png')\n","    plt.show();"],"id":"R9eUY_6S02iG"},{"cell_type":"code","execution_count":3,"metadata":{"id":"rU6sudNP02iK","executionInfo":{"status":"ok","timestamp":1699800316793,"user_tz":0,"elapsed":214,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"PRIME2.0\", \"prtr-deep\"), 'PRIME2.0', 'Prime-Trained Deep')"],"id":"rU6sudNP02iK"},{"cell_type":"code","execution_count":4,"metadata":{"id":"dUAsoJ3S02iL","executionInfo":{"status":"ok","timestamp":1699800320789,"user_tz":0,"elapsed":8,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"PRIME2.0\", \"prtr-pars\"), 'PRIME2.0', 'Prime-Trained Parsimonious')"],"id":"dUAsoJ3S02iL"},{"cell_type":"code","execution_count":8,"metadata":{"id":"1QBXuLiX02iO","executionInfo":{"status":"ok","timestamp":1699800344858,"user_tz":0,"elapsed":318,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"prtr-deep\", \"prtr-pars\"), 'Prime-Trained Deep', 'Prime-Trained Parsimonious')"],"id":"1QBXuLiX02iO"},{"cell_type":"code","execution_count":7,"metadata":{"id":"8nnDX-Ti02iP","executionInfo":{"status":"ok","timestamp":1699800341778,"user_tz":0,"elapsed":6,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"PRIME2.0\", \"parsimonious\"), 'PRIME2.0', 'Parsimonious')"],"id":"8nnDX-Ti02iP"},{"cell_type":"code","execution_count":6,"metadata":{"id":"VXZrYqFv02iQ","executionInfo":{"status":"ok","timestamp":1699800340447,"user_tz":0,"elapsed":251,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"PRIME2.0\", \"deep\"), 'PRIME2.0', 'Deep')"],"id":"VXZrYqFv02iQ"},{"cell_type":"code","execution_count":5,"metadata":{"id":"gaqSF7v402iR","executionInfo":{"status":"ok","timestamp":1699800338420,"user_tz":0,"elapsed":229,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["mainOverlapPlots(getComparisonDF(\"deep\", \"parsimonious\"), 'Deep', 'Parsimonious')"],"id":"gaqSF7v402iR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9y978PPg02iS"},"outputs":[],"source":["# Detecting all immunogenic peptides through classifier\n","# *Use below if data/models are saved to files*\n","A, L = 20, 9\n","classifiers = getAllModels(A, L)\n","model = copy.deepcopy(classifiers[7])\n","model.load_state_dict(torch.load('Classifier/Models/deep.pth')) # *Change path as required*\n","from sklearn.exceptions import UndefinedMetricWarning\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","gene_count0, gene_count1 = [], []\n","for geneName in ref_df['gene']:\n","    X_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number(X_ref_by_gene[geneName])), num_classes=A).type(torch.FloatTensor)\n","    gene_count0.append(np.sum(np.array(y_ref_by_gene[geneName])==0))\n","    gene_count1.append(np.sum(np.array(y_ref_by_gene[geneName])==1))\n","    y_tensor = torch.Tensor(y_ref_by_gene[geneName])\n","\n","    if X_tensor.shape[0] != 0:\n","        # Calculate ROC curve and AUC\n","        fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n","            np.concatenate((np.zeros(len(X_tensor[y_tensor == 0])) + 0,\n","                            np.zeros(len(X_tensor[y_tensor == 1])) + 1), axis=0),\n","            np.concatenate((model(X_tensor[y_tensor == 0]).detach().numpy(),\n","                            model(X_tensor[y_tensor == 1]).detach().numpy()), axis=0)\n","        )\n","        auc = sklearn.metrics.auc(fpr, tpr)\n","    else:\n","        auc = 0\n","    if(np.isnan(auc)):\n","        auc = 0\n","    auc_by_gene[geneName] = auc"],"id":"9y978PPg02iS"},{"cell_type":"code","execution_count":9,"metadata":{"id":"Cmd83nDb02iS","executionInfo":{"status":"ok","timestamp":1699800394621,"user_tz":0,"elapsed":6,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plot Pan-Allelic Classifier Performance by Gene\n","\n","# Calculate the positions for the bars in each group\n","bar_width = 0.2\n","x_positions = np.arange(len(ref_df['gene']))\n","\n","# Create a figure and axes\n","fig, ax1 = plt.subplots(figsize=(10, 6))\n","\n","# Create a twin axes on the right side for the counts\n","ax2 = ax1.twinx()\n","\n","# Plot the bar charts on the right y-axis\n","ax2.bar(x_positions - bar_width/2, gene_count0, width=bar_width, alpha=0.5, color='lime', label='Count (Neg. in Test)')\n","ax2.bar(x_positions + bar_width/2, gene_count1, width=bar_width, alpha=0.5, color='green', label='Count (Pos. in Test)')\n","\n","# Set the range for the right y-axis (counts)\n","ax2.set_ylim(0, max(max(gene_count0), max(gene_count1)))\n","\n","# Label the right y-axis\n","ax2.set_ylabel('Gene Test Data Count')\n","ax2.legend(loc='upper right', fontsize=9)\n","\n","# Plot the line charts for the AUC values on the left y-axis\n","ax1.plot(x_positions, auc_by_gene.values(), label='Deep Classifier', color='blue', marker='o')\n","\n","# Set the ticks and labels for x-axis\n","ax1.set_xticks(x_positions)\n","ax1.set_xticklabels(ref_df['gene'], rotation=45, ha='right', rotation_mode='anchor')\n","\n","# Set the labels and title for the plot\n","ax1.set_xlabel('Gene')\n","ax1.set_ylabel('AUC')\n","ax1.set_ylim(0, 1)\n","ax1.legend(fontsize=8, loc = 'center right')\n","ax1.set_title('Pan-Allelic Classifier Performance by Gene')\n","\n","plt.tight_layout(pad=2)\n","plt.savefig('temp/Pan-Allelic Classifier Performance by Gene', dpi=300)\n","plt.show()\n"],"id":"Cmd83nDb02iS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3p28Q7Pi02iV"},"outputs":[],"source":["# Detecting all immunogenic peptides through classifier\n","A, L = 20, 9\n","classifiers = getAllModels(A, L)\n","model = copy.deepcopy(classifiers[7])\n","model.load_state_dict(torch.load('Classifier/Models/deep.pth')) # *Change path as required*\n","\n","ref_peptides = {}\n","ref_imm = {}\n","my_peptides = {}\n","\n","for geneName in ref_df['gene']:\n","    protein_sequence = ref_df[ref_df['gene'] == geneName]['seq'].values[0]\n","    sequence_length = len(protein_sequence)\n","    peptide_length = 9\n","    ref_peptides[geneName] = []\n","    for i in range(sequence_length - peptide_length + 1):\n","        peptide = protein_sequence[i:i + peptide_length]\n","        if '*' not in peptide and '*' not in protein_sequence[i:i + peptide_length + 1]:\n","            ref_peptides[geneName].append(peptide)\n","\n","    ref_peptides_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number(ref_peptides[geneName])), num_classes=A).type(torch.FloatTensor)\n","    ref_imm[geneName] = model(ref_peptides_tensor).detach().numpy()\n","\n","allScores = []\n","for geneName in ref_df['gene']:\n","    allScores.extend(ref_imm[geneName])\n","for geneName in ref_df['gene']:\n","    my_peptides[geneName] = [peptide for peptide, score in zip(ref_peptides[geneName], ref_imm[geneName]) if score > np.percentile(allScores, 97.5)]\n","\n","# Extract mutations from variants of Deep Classifier epitopes\n","errors = 0\n","error_epitopes = []\n","mutation_rows = {}\n","mutation_count=0\n","for gene, epitopes in my_peptides.items():\n","    mutation_rows[gene] = []\n","    for epitope in epitopes:\n","        for _, row in var_df[var_df['gene'] == gene].iterrows():\n","            if row['gene'] == gene:\n","                seq = row['seq']\n","                if epitope not in seq and epitope not in error_epitopes:\n","                    try:\n","                        mutation_count+=1\n","                        mut_type = getMutationType(epitope, getSeqAligned(epitope, seq), subOnly=1)\n","                        if mut_type != -1:\n","                            if mut_type[1] == -1:\n","                                mutation_type = mut_type[0]\n","                                details = -1\n","                            else:\n","                                mutation_type = mut_type[0]\n","                                details = mut_type[1]\n","                            mutation_rows[gene].append({'epitope': epitope, 'accID': row['accID'], 'mutation': getSeqAligned(epitope, seq), 'mutation_type': mutation_type, 'mutation_type_details': details})\n","                    except ValueError as e:\n","                        error_epitopes.append(epitope)\n","                        errors += 1\n","    print(gene, \"'s  Deep Classifier  mutations  found  -  (\", list(my_peptides.keys()).index(gene)+1, \"/ 27 )\")\n","\n","# Save the dictionary\n","with open('temp/mutation_rows.pkl', 'wb') as file:\n","    pickle.dump(mutation_rows, file)"],"id":"3p28Q7Pi02iV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPZBv_Uz02iX"},"outputs":[],"source":["# Get all epitopes and mutations immunogenicity scores from classifier\n","\n","epi, mut = [], []\n","for gene in mutation_rows.keys():\n","    for epitope in mutation_rows[gene]:\n","        epi.append(epitope['epitope'])\n","        m = epitope['mutation']\n","        if 'X' not in m and len(m) >= 8 and len(m) <= 14:\n","            mut.append(m)\n","epi, mut = np.unique(np.array(epi)), np.unique(np.array(mut))\n","\n","peptides_classifier_scores = {}\n","for peptide in epi:\n","    peptide_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number([peptide])), num_classes=A).type(torch.FloatTensor)\n","    pep_imm = model(peptide_tensor).detach().numpy()[0][0]\n","    peptides_classifier_scores[peptide] = {'Immunogenicity Score': pep_imm}\n","\n","mutations_classifier_scores = {}\n","for mutation in mut:\n","    mutation_tensor = torch.nn.functional.one_hot(torch.LongTensor(convert_number([mutation])), num_classes=A).type(torch.FloatTensor)\n","    mut_imm = model(mutation_tensor).detach().numpy()[0][0]\n","    mutations_classifier_scores[mutation] = {'Immunogenicity Score': mut_imm}"],"id":"mPZBv_Uz02iX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Cgc46IK02iX","outputId":"d1031306-bd48-4875-8432-6b6055db5a9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["NSP1 's  mutation data cleaned  -  ( 1 / 27 )\n","NSP2 's  mutation data cleaned  -  ( 2 / 27 )\n","NSP3 's  mutation data cleaned  -  ( 3 / 27 )\n","NSP4 's  mutation data cleaned  -  ( 4 / 27 )\n","NSP5 's  mutation data cleaned  -  ( 5 / 27 )\n","NSP6 's  mutation data cleaned  -  ( 6 / 27 )\n","NSP7 's  mutation data cleaned  -  ( 7 / 27 )\n","NSP8 's  mutation data cleaned  -  ( 8 / 27 )\n","NSP9 's  mutation data cleaned  -  ( 9 / 27 )\n","NSP10 's  mutation data cleaned  -  ( 10 / 27 )\n","NSP11 's  mutation data cleaned  -  ( 11 / 27 )\n","NSP12 's  mutation data cleaned  -  ( 12 / 27 )\n","NSP13 's  mutation data cleaned  -  ( 13 / 27 )\n","NSP14 's  mutation data cleaned  -  ( 14 / 27 )\n","NSP15 's  mutation data cleaned  -  ( 15 / 27 )\n","NSP16 's  mutation data cleaned  -  ( 16 / 27 )\n","SPIKE 's  mutation data cleaned  -  ( 17 / 27 )\n","NS3 's  mutation data cleaned  -  ( 18 / 27 )\n","E 's  mutation data cleaned  -  ( 19 / 27 )\n","M 's  mutation data cleaned  -  ( 20 / 27 )\n","NS6 's  mutation data cleaned  -  ( 21 / 27 )\n","NS7A 's  mutation data cleaned  -  ( 22 / 27 )\n","NS7B 's  mutation data cleaned  -  ( 23 / 27 )\n","NS8 's  mutation data cleaned  -  ( 24 / 27 )\n","N 's  mutation data cleaned  -  ( 25 / 27 )\n","NS9B 's  mutation data cleaned  -  ( 26 / 27 )\n","NS9C 's  mutation data cleaned  -  ( 27 / 27 )\n"]}],"source":["# Remove mutation data where mutated peptides with 'X' in them and ensure correct length\n","\n","for gene in mutation_rows.keys():\n","    for epi in mutation_rows[gene]:\n","        mutation = epi['mutation']\n","        if 'X' in mutation or len(mutation) < 8 or len(mutation) >14:\n","            mutation_rows[gene].remove(epi)\n","    print(gene, \"'s  mutation data cleaned  -  (\", list(mutation_rows.keys()).index(gene)+1, \"/ 27 )\")"],"id":"4Cgc46IK02iX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4q99OZSf02iY","outputId":"4dff3633-3488-401c-f6f2-db4e8ca5d3a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 500 gene mutations recorded.\n","--- 1000 gene mutations recorded.\n","--- 1500 gene mutations recorded.\n","--- 2000 gene mutations recorded.\n","A total of  2103 gene unique mutations recorded.\n"]}],"source":["# Load immunogenicity scores of peptides and their unique mutations into dataframe\n","\n","count=0\n","mutations_data = []\n","recorded_mutations = []\n","for gene in mutation_rows.keys():\n","    gene_filtered_df = var_df[var_df['gene'] == gene]\n","    for pep in mutation_rows[gene]:\n","        mutation = pep['mutation']\n","        variant = pep['accID']\n","        if mutation not in recorded_mutations and 'X' not in mutation and len(mutation) >= 8 and len(mutation) <= 14:\n","            filtered_df = gene_filtered_df[gene_filtered_df['accID'] == variant]\n","            date = filtered_df['date'].values[0]\n","            location = filtered_df['country'].values[0]\n","            lab = filtered_df['lab'].values[0]\n","            recorded_mutations.append(mutation)\n","            gene = gene\n","            peptide = pep['epitope']\n","            score_peptide = float((peptides_classifier_scores)[peptide]['Immunogenicity Score'])\n","            score_mutation = float((mutations_classifier_scores)[mutation]['Immunogenicity Score'])\n","            if score_mutation / score_peptide <= 0:\n","                if score_mutation > score_peptide:\n","                    evasion_score = np.log(abs(score_mutation) / (score_peptide + 2 * score_mutation))\n","            else:\n","                evasion_score = np.log(score_mutation / score_peptide)\n","            mutations_data.append([variant, date, location, lab, gene, peptide, mutation, score_peptide, score_mutation, evasion_score])\n","            count+=1\n","            if count%500==0:\n","                print('---', count, 'gene mutations recorded.')\n","print('A total of ', count, 'gene unique mutations recorded.')\n","diff_df = pd.DataFrame(mutations_data, columns=['variant', 'date', 'location', 'lab', 'gene', 'peptide', 'mutation', 'score_peptide', 'score_mutation', 'evasion_score'])\n","filtered_diff_df = diff_df.drop_duplicates(subset=['peptide', 'mutation', 'evasion_score'], keep='first')"],"id":"4q99OZSf02iY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfIhKItK02iZ"},"outputs":[],"source":["# Need to run this for ~an hour~ to record total mutations observed from peptides identified from deep classifier\n","\n","# # Load immunogenicity scores of peptides and their unique mutations into dataframe\n","\n","# count, total=0,0\n","# mutations_data = []\n","# for gene in mutation_rows.keys():\n","#     gene_filtered_df = var_df[var_df['gene'] == gene]\n","#     for pep in mutation_rows[gene]:\n","#         total +=1\n","# progress_bar = tqdm(total=total, desc='Progress')\n","# for gene in mutation_rows.keys():\n","#     gene_filtered_df = var_df[var_df['gene'] == gene]\n","#     for pep in mutation_rows[gene]:\n","#         progress_bar.update(1)\n","#         mutation = pep['mutation']\n","#         variant = pep['accID']\n","#         if 'X' not in mutation and len(mutation) >= 8 and len(mutation) <= 14:\n","#             filtered_df = gene_filtered_df[gene_filtered_df['accID'] == variant]\n","#             date = filtered_df['date'].values[0]\n","#             location = filtered_df['country'].values[0]\n","#             lab = filtered_df['lab'].values[0]\n","#             gene = gene\n","#             peptide = pep['epitope']\n","#             score_peptide = float((peptides_classifier_scores)[peptide]['Immunogenicity Score'])\n","#             score_mutation = float((mutations_classifier_scores)[mutation]['Immunogenicity Score'])\n","#             if score_mutation / score_peptide <= 0:\n","#                 if score_mutation > score_peptide:\n","#                     evasion_score = np.log(abs(score_mutation) / (score_peptide + 2 * score_mutation))\n","#             else:\n","#                 evasion_score = np.log(score_mutation / score_peptide)\n","#             mutations_data.append([variant, date, location, lab, gene, peptide, mutation, score_peptide, score_mutation, evasion_score])\n","# #             count+=1\n","# #             if count%500==0:\n","# #                 print('---', count, 'gene mutations recorded.')\n","\n","# print('A total of ', count, 'gene unique mutations recorded.')\n","# diff_df = pd.DataFrame(mutations_data, columns=['variant', 'date', 'location', 'lab', 'gene', 'peptide', 'mutation', 'score_peptide', 'score_mutation', 'evasion_score'])\n","# filtered_diff_df = diff_df.drop_duplicates(subset=['peptide', 'mutation', 'evasion_score'], keep='first')"],"id":"bfIhKItK02iZ"},{"cell_type":"code","execution_count":10,"metadata":{"id":"f8z3U8uj02ia","executionInfo":{"status":"ok","timestamp":1699800756607,"user_tz":0,"elapsed":310,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plotting number of unique mutations per gene\n","\n","geneCount = []\n","for gene in mutation_rows.keys():\n","    geneCount.append(len(filtered_diff_df[filtered_diff_df['gene'] == gene]))\n","\n","plt.figure(figsize=(9, 4))\n","x_positions = np.arange(len(ref_df['gene']))\n","plt.bar(x_positions, geneCount)\n","\n","# Add count labels on top of each bar\n","for i, count in enumerate(geneCount):\n","    plt.text(i, count, count, ha='center', va='bottom', fontsize=8)\n","\n","plt.xticks(x_positions, ref_df['gene'], rotation=45, ha='right', rotation_mode='anchor')\n","plt.xlabel('Gene')\n","plt.ylabel('Count')\n","plt.tight_layout(pad=1)\n","plt.title('Count of Unique Mutated Deep Classifier Peptides by Gene - Total = ' + str(sum(geneCount)))\n","plt.savefig('temp/count2.png', dpi=300, bbox_inches='tight')\n","plt.show()"],"id":"f8z3U8uj02ia"},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8VjWQCU02ib"},"outputs":[],"source":["# SPIKE, N, M, NSP3, NSP4, NSP12, NSP13, NS3, NS8\n","# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10036809/"],"id":"P8VjWQCU02ib"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfA_o23_02ic"},"outputs":[],"source":["# Gathering Mutation Details Data\n","\n","recorded_mutations = []\n","position_changes, residue_mutations = {}, {}\n","for gene in mutation_rows.keys():\n","    for epi in mutation_rows[gene]:\n","        mutation = epi['mutation']\n","        if mutation not in recorded_mutations and 'X' not in mutation and len(mutation) >= 8 and len(mutation) <= 14:\n","            count+=1\n","            recorded_mutations.append(mutation)\n","            epitope_residue, mutation_residue = epi['mutation_type_details'][0][1], epi['mutation_type_details'][0][2]\n","            if epitope_residue not in residue_mutations:\n","                residue_mutations[epitope_residue] = []\n","                residue_mutations[epitope_residue].append(mutation_residue)\n","            else:\n","                residue_mutations[epitope_residue].append(mutation_residue)\n","            if len(mutation) not in position_changes:\n","                position_changes[len(mutation)] = []\n","                position_changes[len(mutation)].append(epi['mutation_type_details'][0][0])\n","            else:\n","                position_changes[len(mutation)].append(epi['mutation_type_details'][0][0])"],"id":"NfA_o23_02ic"},{"cell_type":"code","execution_count":11,"metadata":{"id":"VppIkDBz02ic","executionInfo":{"status":"ok","timestamp":1699800808237,"user_tz":0,"elapsed":9,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["from matplotlib.path import Path\n","from matplotlib.patches import PathPatch, FancyArrowPatch\n","\n","def plot_chord_diagram(residue_mutations):\n","    residues = list(residue_mutations.keys())\n","    num_residues = len(residues)\n","\n","    # Count occurrences of mutated residues for each original residue\n","    counts = np.zeros((num_residues, num_residues))\n","    for i, residue in enumerate(residues):\n","        mutations = residue_mutations[residue]\n","        for mutation in mutations:\n","            j = residues.index(mutation)\n","            counts[i, j] += 1\n","\n","    # Normalize counts to calculate angles\n","    angles = 2 * np.pi * counts / counts.sum(axis=1, keepdims=True)\n","\n","    fig, ax = plt.subplots(figsize=(8, 8))\n","    ax.set_xlim(-1, 1)\n","    ax.set_ylim(-1, 1)\n","    ax.axis('off')\n","\n","    # Draw circles for residues\n","    circle_positions = np.linspace(0, 2 * np.pi, num_residues, endpoint=False)\n","    x = np.cos(circle_positions)\n","    y = np.sin(circle_positions)\n","    labels = residues\n","\n","    for i in range(num_residues):\n","        ax.plot(x[i], y[i], marker='o', markersize=20, color='skyblue')\n","        ax.text(1.1 * x[i], 1.1 * y[i], labels[i], fontsize=14, ha='center', va='center')\n","\n","    # Draw shaded lines representing mutations with line thickness based on occurrences\n","    max_occurrences = np.max(counts)\n","    for i in range(num_residues):\n","        for j in range(num_residues):\n","            if i != j:\n","                alpha = np.clip(angles[i, j], 0, 1)  # Clip alpha values to the valid range\n","                linewidth = 0.5 + 4 * (counts[i, j] / max_occurrences)  # Adjust line thickness based on occurrences\n","                path = Path([(x[i], y[i]), (x[j], y[j])])\n","                patch = PathPatch(path, facecolor='skyblue', edgecolor='gray', alpha=alpha, linewidth=linewidth)\n","                ax.add_patch(patch)\n","\n","                arrow_start = (x[i], y[i])\n","                arrow_end = (x[j], y[j])\n","                arrow_dx = arrow_end[0] - arrow_start[0]\n","                arrow_dy = arrow_end[1] - arrow_start[1]\n","                arrow_style = \"->\"  # Set the arrow style\n","                arrow_color = \"gray\"  # Set the arrow color\n","                arrow_alpha = alpha  # Set the arrow alpha value\n","                arrow_linewidth = linewidth  # Set the arrow linewidth\n","                ax.annotate(\"\", arrow_start, arrow_end, arrowprops=dict(arrowstyle=arrow_style, color=arrow_color,\n","                                                                        alpha=arrow_alpha, linewidth=arrow_linewidth))\n","    plt.savefig('temp/chord.png', dpi=300, bbox_inches='tight')\n","    plt.show();\n","\n","plot_chord_diagram(residue_mutations)"],"id":"VppIkDBz02ic"},{"cell_type":"code","execution_count":12,"metadata":{"id":"Dcuhzm4l02ie","executionInfo":{"status":"ok","timestamp":1699800817567,"user_tz":0,"elapsed":238,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plotting matrix of epitope residue mutations\n","\n","# Get sorted list of epitope residues\n","epitope_residues = sorted(residue_mutations.keys())\n","\n","# Get sorted list of mutated residues\n","mutated_residues = sorted(set([residue for residues in residue_mutations.values() for residue in residues]))\n","\n","# Create an empty grid with zeros\n","grid = np.zeros((len(mutated_residues), len(epitope_residues)))\n","\n","# Count occurrences of mutated residues for each epitope residue\n","for i, epitope_residue in enumerate(epitope_residues):\n","    for j, mutated_residue in enumerate(mutated_residues):\n","        grid[j, i] = residue_mutations[epitope_residue].count(mutated_residue)\n","\n","# Create the grid plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","im = ax.imshow(grid, cmap='Reds')\n","\n","# Set x-axis and y-axis labels\n","ax.set_xticks(np.arange(len(epitope_residues)))\n","ax.set_yticks(np.arange(len(mutated_residues)))\n","ax.set_xticklabels(epitope_residues)\n","ax.xaxis.tick_top()\n","ax.set_yticklabels(mutated_residues)\n","\n","# Set overall x-axis and y-axis labels\n","ax.set_xlabel('Epitope Residues')\n","ax.xaxis.set_label_position('top')\n","ax.set_ylabel('Mutation Residues')\n","\n","# Add count numbers to the grid\n","for i in range(len(mutated_residues)):\n","    for j in range(len(epitope_residues)):\n","        text = ax.text(j, i, int(grid[i, j]), ha='center', va='center', color='black')\n","\n","# Set title\n","ax.set_title('Residue Mutation Matrix')\n","\n","# Create a colorbar\n","cbar = fig.colorbar(im, ax=ax, label='Counts')\n","\n","plt.savefig('temp/gridResidues.png', dpi=300, bbox_inches='tight')\n","# Display the plot\n","plt.show()\n"],"id":"Dcuhzm4l02ie"},{"cell_type":"code","execution_count":13,"metadata":{"id":"qBPl1KMC02if","executionInfo":{"status":"ok","timestamp":1699800824289,"user_tz":0,"elapsed":6,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plotting Mutation Position Counts\n","\n","for i in list(position_changes.keys()):\n","    positions = position_changes[i]\n","    unique_nums, counts = np.unique(positions, return_counts=True)\n","    fig, ax = plt.subplots(figsize=((i/9)*12.25, 1.2))\n","    ax.set_xlim(0, i+1)\n","    ax.set_ylim(0, 1)\n","    # Iterate over unique numbers and their counts\n","    for num, count in zip(unique_nums, counts):\n","        # Calculate the circle radius and color based on the count\n","        radius = count / len(positions) * 2.5\n","        color = count / len(positions) * 3\n","        # Draw the circle\n","        circle = plt.Circle((num, 0.5), radius, fc='white', edgecolor='black')\n","        ax.add_patch(circle)\n","        circle = plt.Circle((num, 0.5), radius, fc='yellow', alpha=1, edgecolor='black')\n","        ax.add_patch(circle)\n","        circle = plt.Circle((num, 0.5), radius, fc='red', alpha=color)\n","        ax.add_patch(circle)\n","        # Add text inside the circle\n","        ax.text(num, 0.5, f\"{num}:\\n{count}\", ha='center', va='center', color='black', alpha=1, fontweight='medium')\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","    ax.set_title('Counts of Position Mutations for ' + str(i) + '-mers Deep Classifier Peptides')\n","    plt.savefig('temp/'+str(i)+'circ.png', dpi=300, bbox_inches='tight')\n","    plt.show()"],"id":"qBPl1KMC02if"},{"cell_type":"code","execution_count":14,"metadata":{"id":"22832wEe02ig","executionInfo":{"status":"ok","timestamp":1699800831052,"user_tz":0,"elapsed":5,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Create a distribution plot for the Deep Classifier immunogenicity cost of the mutations\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","ax.hist(filtered_diff_df['evasion_score'], bins=100, label='Evasion Score')\n","ax.set_xlabel('Mutation Immunogenicity Evasion Score')\n","ax.set_ylabel('Count')\n","ax.set_title(\"Distribution of Unique Mutations' Evasion Score\")\n","ax.axvline(x=0, color='red', linestyle='--', label='Evasion Score = 0')\n","ax.axvline(x=np.percentile(filtered_diff_df['evasion_score'], 1), color='blue', linestyle='--', label='1st Percentile')\n","ax.legend()\n","plt.savefig('temp/evasion1.png', dpi=300, bbox_inches='tight')\n","plt.show()"],"id":"22832wEe02ig"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fk9yDYaQ02ig","outputId":"aee36ad9-7d93-4493-812e-7483fa85bfa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2% most dangerous mutated peptides - according to Evasion Score:\n","['MFLSTLMKC', 'LQKKKVNIN', 'LQKEKVTSI', 'IEAMMFTSD', 'DYTVIEVQG', 'SDDYIAING', 'LSGHNLAKH', 'EVQGYKSVN', 'DNLKTLLSL', 'LYGEVITFD', 'LEGEVITFD', 'LKFSPPALQ', 'LKFYPPALQ', 'LKFTPPALQ', 'LKFIPPALQ', 'CERVLNVVC', 'KPLEFGVTS', 'VADAVIKTL', 'IAKYSVKSV', 'VIKNFATSI', 'NFVQMAPIS', 'LDNYYRKDN', 'NSRIKASMP', 'AYFDTWFSQ', 'TIYSLLKDC', 'DTDLTKPYI', 'DAQSFLKPG', 'DATTAYANS', 'ANEYRLYLD', 'TYGVCLFWN', 'SDRVVFVLW', 'NVTGLFKDC', 'NFWNTFIRL', 'LLPLVSIQC', 'LLPLVSSHC', 'LYPLSETKC', 'LPPLSETKC', 'LTGIAVEQD', 'WFHAISGTN', 'MYLNGPQNQ', 'SSRTSTPGS', 'SLRTSTPGS', 'SSRSSTPGS']\n"]}],"source":["# Most dangerous mutated peptides\n","\n","mutations_dangerous = filtered_diff_df[filtered_diff_df['evasion_score'] < np.percentile([x for x in filtered_diff_df['evasion_score'] if str(x) != 'nan'], 2)]['mutation'].tolist()\n","\n","print('2% most dangerous mutated peptides - according to Evasion Score:')\n","print(mutations_dangerous)"],"id":"Fk9yDYaQ02ig"},{"cell_type":"code","execution_count":15,"metadata":{"id":"lrErDgWM02ih","executionInfo":{"status":"ok","timestamp":1699800836992,"user_tz":0,"elapsed":313,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["exp_ver=[]\n","for pep in filtered_diff_df['peptide']:\n","    if pep in X:\n","        exp_ver.append(pep)\n","\n","\n","exp_vr_df = filtered_diff_df[filtered_diff_df['peptide'].isin(exp_ver)]\n","\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","ax.hist(exp_vr_df['evasion_score'], bins=100, label='Evasion Score')\n","ax.set_xlabel('Experimentally-Verified Mutations Immunogenicity Evasion Score')\n","ax.set_ylabel('Count')\n","ax.set_title(\"Distribution of Experimentally-Verified Mutations' Evasion Score\")\n","ax.axvline(x=0, color='red', linestyle='--', label='Evasion Score = 0')\n","#ax.axvline(x=np.percentile(filtered_diff_df['evasion_score'], 1), color='blue', linestyle='--', label='1st Percentile')\n","ax.legend()\n","\n","plt.show()\n","exp_vr_df['peptide'].tolist()[np.argmin(exp_vr_df['evasion_score'])]"],"id":"lrErDgWM02ih"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSrZkGZQ02ii"},"outputs":[],"source":["# None of the most dangerous peptides (identified by my deep classifier) are experimentally-verified (via IEDB) - one is a subset of another.\n","# There are 69 peptides out of all of the peptides identified by my deep classifier with mutations that are experimentally-verified\n","# One has a significantly low evasion score: NLWNTFTRL\n"],"id":"cSrZkGZQ02ii"},{"cell_type":"code","execution_count":16,"metadata":{"id":"OuzoTHA402ij","executionInfo":{"status":"ok","timestamp":1699800865355,"user_tz":0,"elapsed":5,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Check frequency of most dangerous mutations over time\n","\n","# Filter the DataFrame to include only rows with peptides in `rank_mutations_dangerous`\n","most_dangerous_df = var_df[var_df['seq'].str.contains('|'.join(mutations_dangerous))]\n","\n","# Group the filtered DataFrame by date and count the occurrences\n","grouped_df = most_dangerous_df.groupby('date').size().reset_index(name='count')\n","\n","# Get the counts per date from the original DataFrame\n","var_df_counts = var_df['date'].value_counts()\n","\n","# Normalise the counts by the total number of occurrences per date in var_df\n","grouped_df['normalised_count'] = grouped_df.apply(lambda row: row['count'] / var_df_counts[row['date']], axis=1)\n","\n","# Convert the 'date' column to datetime format\n","grouped_df['date'] = pd.to_datetime(grouped_df['date'])\n","\n","# Plot the counts over time\n","plt.figure(figsize=(14, 5))\n","plt.plot(grouped_df['date'], grouped_df['normalised_count'])\n","plt.xlabel('Date')\n","plt.ylabel('Count')\n","plt.title('Normalised Count of 2% Most Dangerous Mutations over Time')\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.savefig('temp/mut_counts.png', dpi=300, bbox_inches='tight')\n","plt.show();"],"id":"OuzoTHA402ij"},{"cell_type":"code","execution_count":17,"metadata":{"id":"TJgn87cG02il","executionInfo":{"status":"ok","timestamp":1699800872235,"user_tz":0,"elapsed":9,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plot GISAID Submissions of Deep Classifier Peptides by Country\n","\n","# Get all country names\n","locations_deep = filtered_diff_df['location'].tolist()\n","locations_all = var_df['country'].tolist()\n","\n","# Map to correct country names\n","country_name_mapping = {\n","    'Aruba': 'Netherlands',\n","    'Bonaire': 'Netherlands',\n","    'Bosnia and Herzegovina': 'Bosnia and Herz.',\n","    'Bra': 'Brazil',\n","    'Braz': 'Brazil',\n","    'Brazi': 'Brazil',\n","    'Bulgari': 'Bulgaria',\n","    'Bulgar': 'Bulgaria',\n","    'Colo': 'Colombia',\n","    'Colombi': 'Colombia',\n","    'Curacao': 'Netherlands',\n","    'Czech Republic': 'Czechia',\n","    'Eswatini': 'eSwatini',\n","    'Esto': 'Estonia',\n","    'French Guiana': 'France',\n","    'Germa': 'Germany',\n","    'Gha': 'Ghana',\n","    'Ghan': 'Ghana',\n","    'Gibraltar': 'United Kingdom',\n","    'Guadeloupe': 'France',\n","    'Hong Kong': 'China',\n","    'Mauritius': 'France',\n","    'Martinique': 'France',\n","    'Mayotte': 'France',\n","    'P': 'Poland',\n","    'Pola': 'Poland',\n","    'Polan': 'Poland',\n","    'Reunion': 'France',\n","    'UK': 'United Kingdom',\n","    'USA': 'United States of America',\n","}\n","\n","locations_deep = [country_name_mapping.get(location, location) for location in locations_deep]\n","locations_all = [country_name_mapping.get(location, location) for location in locations_all]\n","\n","# Calculate the ratio of counts for each country\n","country_counts = {'Country': [], 'Ratio': []}\n","added_countries = set()\n","for country in locations_deep:\n","    if country not in added_countries:\n","        count_deep = locations_deep.count(country)\n","        count_all = locations_all.count(country)\n","        ratio = count_deep / count_all if count_all != 0 and count_all>50 else 0\n","        country_counts['Country'].append(country)\n","        country_counts['Ratio'].append(ratio)\n","        added_countries.add(country)\n","gdf = gpd.GeoDataFrame(country_counts)\n","\n","# Read the world shapefile (or any other shapefile containing country boundaries)\n","world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n","\n","# Merge the world shapefile with the ratio data\n","merged = world.merge(gdf, left_on='name', right_on='Country', how='left')\n","\n","# Set missing ratios to zero\n","merged['Ratio'] = merged['Ratio'].fillna(0)\n","\n","# Create the choropleth map\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Create a colormap with autumn colors\n","cmap_colors = ['white'] + list(plt.cm.autumn_r(range(256)))\n","cmap = ListedColormap(cmap_colors)\n","\n","# Plot the countries with ratios\n","merged.plot(column='Ratio', cmap=cmap, linewidth=0.25, ax=ax, edgecolor='black', legend=True)\n","\n","# Remove x and y tick markers, and x and y tick labels\n","ax.set_xticks([])\n","ax.set_yticks([])\n","ax.set_xticklabels([])\n","ax.set_yticklabels([])\n","\n","# Remove axis labels\n","ax.set_xlabel('')\n","ax.set_ylabel('')\n","ax.set_title('Ratio of GISAID Submissions of Mutations of Deep Classifier Peptides by Country')\n","\n","# Save the map as PNG\n","plt.savefig('temp/map1.png', dpi=300, bbox_inches='tight')\n","\n","plt.show()\n"],"id":"TJgn87cG02il"},{"cell_type":"code","execution_count":18,"metadata":{"id":"yIOicgvA02im","executionInfo":{"status":"ok","timestamp":1699800876078,"user_tz":0,"elapsed":7,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["plt.figure(figsize=(12, 3))\n","plt.bar(country_counts['Country'], country_counts['Ratio']);\n","plt.xticks(rotation=90);"],"id":"yIOicgvA02im"},{"cell_type":"code","execution_count":19,"metadata":{"id":"N5433bbw02im","executionInfo":{"status":"ok","timestamp":1699800879490,"user_tz":0,"elapsed":8,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["# Plot time-series plots of Deep Classifier mutations and global new daily cases\n","\n","# Count occurrences of dates from all GISAID variant data\n","all_dates = var_df['date'].tolist()\n","all_dates_count = Counter(all_dates)\n","\n","# Normalise counts in all_dates\n","total_samples = len(all_dates)  # Assuming 27 as the total number of samples\n","all_dates_count = {date: count / 27 for date, count in all_dates_count.items()}\n","\n","# Count occurrences of dates from all Deep-Classifier-mutation-filtered variant data\n","filtered_dates = filtered_diff_df['date'].tolist()\n","filtered_dates_count = Counter(filtered_dates)\n","\n","# Normalise counts in filtered_dates relative to all_dates\n","normalised_date_counts = {date: count / all_dates_count[date] for date, count in filtered_dates_count.items()}\n","\n","# Sort the dictionary by date in chronological order\n","sorted_dates = sorted(normalised_date_counts.keys())\n","\n","# Extract the sorted dates and corresponding normalized counts\n","sorted_counts = [normalised_date_counts[date] for date in sorted_dates]\n","\n","# Convert the date strings to datetime objects\n","dates = [datetime.strptime(date, '%Y-%m-%d') for date in sorted_dates]\n","\n","# Plot the time-series data\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Variant emergence lines\n","filtered_variant_dates = [['2020-09-15', 'Alpha'], ['2020-12-15', 'Lambda'], ['2020-05-15', 'Beta'], ['2020-11-15', 'Gamma'], ['2020-10-15', 'Delta'], ['2020-03-15', 'Epsilon']]\n","for variant in filtered_variant_dates:\n","    variant_date = datetime.strptime(variant[0], '%Y-%m-%d')\n","    variant_label = variant[1]\n","    ax.axvline(x=variant_date, linestyle='--', color='red', alpha=0.5)\n","    ax.text(variant_date, max(sorted_counts), variant_label, color='red', rotation=90, va='top')\n","\n","ax.plot(dates, sorted_counts, label='Normalised Counts', color='orange')\n","ax.set_xlabel('Date')\n","ax.set_ylabel('Normalised Count')\n","ax.set_title('Time-Series Plot of Normalised Frequency of Submitted Deep Classifier Peptide Mutations')\n","\n","# Set the x-axis tick labels\n","date_formatter = DateFormatter('%Y-%m-%d')\n","ax.xaxis.set_major_formatter(date_formatter)\n","ax.xaxis.set_major_locator(MonthLocator())\n","fig.autofmt_xdate(rotation=45)\n","\n","plt.tight_layout()\n","plt.legend()\n","plt.savefig('temp/time_muts.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# Plot Global Daily New COVID-19 Cases Data\n","\n","world_dates, world_cases = [], []\n","with open('Mutation Analysis/world-covid-daily-cases.csv', 'r') as file:\n","    reader = csv.reader(file)\n","    for row in reader:\n","        world_dates.append(datetime.strptime(row[0], '%Y-%m-%d'))\n","        world_cases.append(int(row[1]))\n","\n","fig, ax = plt.subplots(figsize=(11.5, 6))\n","ax.plot(world_dates, world_cases, label='New Daily Cases', color='black')\n","ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n","\n","# Iterate over variant dates and add vertical lines with labels\n","variant_dates = [['2020-09-15', 'Alpha'], ['2020-12-15', 'Lambda'], ['2020-05-15', 'Beta'], ['2020-11-15', 'Gamma'], ['2020-10-15', 'Delta'], ['2020-03-15', 'Epsilon']]\n","for variant in variant_dates:\n","    variant_date = datetime.strptime(variant[0], '%Y-%m-%d')\n","    variant_label = variant[1]\n","    ax.axvline(x=variant_date, linestyle='-.', color='red', alpha=0.5)\n","    ax.text(variant_date, ax.get_ylim()[1] * 0.15, variant_label, color='red', rotation=90, va='bottom')\n","\n","fig.autofmt_xdate()\n","ax.set_xlabel('Date')\n","ax.set_ylabel('Count')\n","ax.set_title('Global New Daily Cases by Time')\n","ax.legend()\n","plt.savefig('temp/time_world.png', dpi=300, bbox_inches='tight')\n","plt.show()\n"],"id":"N5433bbw02im"},{"cell_type":"code","execution_count":20,"metadata":{"id":"yIbnmrii02in","executionInfo":{"status":"ok","timestamp":1699800890155,"user_tz":0,"elapsed":6,"user":{"displayName":"Shafaan Jafri","userId":"11281166051345270474"}}},"outputs":[],"source":["plt.hist(filtered_diff_df[(filtered_diff_df['date'] > '2020-07-10') & (filtered_diff_df['date'] < '2020-09-01')]['location']);"],"id":"yIbnmrii02in"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVP7-FWz02io"},"outputs":[],"source":[],"id":"wVP7-FWz02io"}],"metadata":{"kernelspec":{"display_name":"mresenv","language":"python","name":"mresenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}